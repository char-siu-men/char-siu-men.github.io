<!doctype html><html dir=ltr lang=ja><meta charset=utf-8><meta http-equiv=x-ua-compatible content="ie=edge"><link rel=alternate hreflang=ja href=https://www.altus5.co.jp/ ><title>機械学習モデルの汎化を妨げる過学習とは？ - 旗揚げ画像の二値分類を例に | ALTUS-FIVE</title><meta name=description content=この記事では機械学習に関連する以下のトピックについて解説し、機械学習を学んだことのない方が、汎化と過学習に関する観念的な理解を深めることを目指します。><meta name=viewport content="width=device-width,initial-scale=1"><meta property=og:title content="機械学習モデルの汎化を妨げる過学習とは？ - 旗揚げ画像の二値分類を例に | ALTUS-FIVE"><meta property=og:type content=website><meta property=og:url content=https://www.altus5.co.jp><meta property=og:description content=この記事では機械学習に関連する以下のトピックについて解説し、機械学習を学んだことのない方が、汎化と過学習に関する観念的な理解を深めることを目指します。><meta property=og:site_name content=ALTUS-FIVE><meta property=og:image content=https://www.altus5.co.jp/images/ogp.png><meta name=twitter:card content=summary><meta name=twitter:url content=https://www.altus5.co.jp><meta name=twitter:title content="機械学習モデルの汎化を妨げる過学習とは？ - 旗揚げ画像の二値分類を例に | ALTUS-FIVE"><meta name=twitter:description content=この記事では機械学習に関連する以下のトピックについて解説し、機械学習を学んだことのない方が、汎化と過学習に関する観念的な理解を深めることを目指します。><meta name=twitter:image content=https://www.altus5.co.jp/images/ogp.png><link rel=apple-touch-icon sizes=180x180 href=/images/apple_touch_icon180x180.png><link rel=apple-touch-icon sizes=152x152 href=/images/apple_touch_icon152x152.png><link rel=apple-touch-icon sizes=120x120 href=/images/apple_touch_icon120x120.png><link rel=apple-touch-icon sizes=76x76 href=/images/apple_touch_icon76x76.png><link href=https://www.altus5.co.jp/feed.xml rel=alternate type=application/atom+xml><link rel=stylesheet href=/styles/common.css><link rel=stylesheet href=/styles/blog.css><body><noscript><iframe src="//www.googletagmanager.com/ns.html?id=GTM-5WGNWC" height=0 width=0 style=display:none;visibility:hidden></iframe></noscript><script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    '//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-5WGNWC');</script><!--[if lt IE 9]>
    <p class="browserupgrade">
      <strong>古い</strong>ブラウザをご使用されています。
      本サイトを快適に閲覧頂くために、<a href="http://browsehappy.com/">新しいブラウザにアップグレード</a>してください。
    </p>
  <![endif]--><header id=_header><nav class="w_const cf"><h1 class=logo_head><a href=/ ><img src=/images/logo_header.png alt=ALTUS-FIVE（アルタスファイブ）></a></h1><ul class=links><li class=link><a href=/#introduction>アルタスファイブとは</a><li class=link><a href=/#feature>強み</a><li class=link><a href=/#service>サービス</a><li class=link><a href=/#performance>実績</a><li class=link><a href=/#example>開発事例</a><li class=link><a href=/blog/ >ブログ</a><li class=link><a href=/recruit/ >採用情報</a><li class=link><a href=/company/ >会社概要</a><li class="link link_contact"><a href=/contact/ >お問い合わせ</a></ul></nav></header><div id=blog_page class=wrap_all><article id=blog class=article><section class="blog__title w_const"><span>機械学習モデルの汎化を妨げる過学習とは？ - 旗揚げ画像の二値分類を例に</span></section><div class="article__conts w_const cf"><div id=blog-content><div id=blog-subtitle class=cf><div id=blog-date>2016/11/28</div><div id=blog-tags><ul class=tag-uline><li class="tag-uline-label tag__0"><a href=/blog/tag/%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%9F%E3%83%B3%E3%82%B0%E6%8A%80%E8%A1%93%E7%B7%8F%E8%A6%A7/ >プログラミング技術総覧</a><li class="tag-uline-label tag__3"><a href=/blog/tag/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92/ >機械学習</a></ul></div></div><div class=markdown-body><h2 id=->目的</h2><p>この記事では機械学習に関連する以下のトピックについて解説し、機械学習を学んだことのない方が、汎化と過学習に関する観念的な理解を深めることを目指します。<ul><li>予測モデルの汎化能力<li>汎化能力の向上を妨げる過学習という現象</ul><p>観念的なわかりやすさを重視しているため、細部に誤りや不正確な点があるかもしれません。<br>不適切な点がございましたら、ご教示頂ければ幸いです。<p>以下、この記事では画像の二値分類を例に取ります。<br>ですが、汎化と過学習に関する知識の適用範囲は画像認識の分野にとどまりません。<ul><li>予測モデルにおいては、データ誤差を抑えることが本質的な課題であり、過学習はその目標達成を妨げる<li>実際に機械学習を行う際、適切なデータサイズやエポック数（学習回数）を決めるために過学習に関する知識が必要である</ul><p>以上のことから、モデルの汎化能力と過学習に関する理解は機械学習について学ぶ上で十分に汎用的であり、初学者が理解を深める段階から実用レベルに至るまで、幅広く役に立ちます。<h2 id=->旗揚げ画像の二値分類</h2><p>以降の議論では、画像の二値分類をテーマとし、<ul><li>汎化精度を上げるとはどういうことか？<li>過学習とはどんな現象のことか？</ul><p>を説明していきます。<p>ここでは二値分類の対象として、以下のような小さなサイズの「旗揚げ画像」を取り上げます。<p><img src=/images/blog/ol/image1.png alt="図1: 入力例"><p>受け付ける入力は8*8ピクセルで、情報がRGB形式で与えられる任意のものとします。 （よってこの記事に示す入力例よりも、遥かに多様な入力が考えられることに注意してください。）<p>図1のような画像に「赤を揚げている」「白を揚げている」というラベルを付与したものを訓練データとし、教師つき学習を行うこととします。<p><img src=/images/blog/ol/image2.png alt="図2: いろいろな入力例"><p>学習の目的は、未知の入力画像に対し、赤と白のどちらを揚げている画像かを適切に判定出来るようになることです。<h3 id=->補足：二値分類とは</h3><p>二値分類とは、与えられたデータを、事前に与えられた二つのラベルに振り分けることを指します。<p>画像認識においては、以下のような例が有名です。<ul><li>男性か女性かを見分ける<li>犬か猫かを見分ける</ul><p>画像認識以外の二値分類として、以下のような例が有名です。<ul><li>メールをスパムと非スパムに区別する<li>ある患者のデータから、特定の疾病を持つかどうかを区別する</ul><h3 id=->二値分類における主流のモデル - 事後確率の計算</h3><p>ここで取り上げている二値分類や、より多くのクラスに分ける他クラス分類においては、入力に対し「事後確率」を計算するのが主流の方法です。<p><img src=/images/blog/ol/image3.png alt="図3: 各入力に対する事後確率の例"><p>ここで「事後確率」とは「データが与えられた後の確率」という意味であり、「ある特定のデータが、赤であるか白であるかについて、モデルによって推定された結果」であると解釈して頂いて問題ありません。学習途中においても、事後確率を算出することが可能です。<p>ここで機械学習モデルの中身についてはブラックボックスとしていますが、畳み込みニューラルネットワーク(CNN)が古典的なモデルとして有名です。<p><a href=http://qiita.com/icoxfog417/items/5fd55fad152231d706c2>Convolutional Neural Networkとは何なのか</a><h3 id=->学習の枠組み - 最尤推定</h3><p>各入力データに対して事後確率を求めるモデルでは、学習の各段階において尤度(likelihood)を求めることが出来ます。<p>尤度は、それぞれの入力データが持つ「正解のラベル」に対し、その時点のモデルが算出した事後確率の積を取ったものと考えられます。<p><img src=/images/blog/ol/image4.png alt="図4: 尤度の計算"><p>ここでは二つの入力データに対する尤度を計算しており、0.72 = 72%という値が算出されています。<p>事後確率を求める機械学習モデルは、学習を繰り返すことで尤度を増加させるよう設計されています。<p>ここでは訓練データに対して尤度を高める過程を適合(fitting)といい、下に示す図5は学習の結果、訓練データに極めて適合した状態を模式的に表しています。<p><img src=/images/blog/ol/image5.png alt="図5: 訓練データへの適合度が高い状態"><p>各入力に対し、正解のラベルに1に近い事後確率を割り振っていますね。<p>図5はいわば、学習によって、訓練データに対して百発百中の精度を持つようになった状態です。<p>これが望ましいことかどうかを、以下の段落で見ていきます。<h3 id=->未知の入力に対する推定 - 汎化能力</h3><p>図4、5だけを見ると、訓練データへの適合度が高い図5の状態の方が望ましいように見えます。<p>しかし、このモデルの目的は「未知の入力画像に対し、赤と白のどちらを揚げている画像かを適切に判定出来るようになること」なのでした。<p>ですので、訓練データに含まれていない画像、すなわち「テストデータ」に対して推定を行ってみるべきでしょう。<p><img src=/images/blog/ol/image6.png alt="図6: 未知の入力への適用"><p>図6は、図4のモデルに対して、 $ x&#39; $ という未知のテストデータを入力した結果を示しています（もちろん、実際のテストでは複数のテストデータを入力します）。<p>正解のラベル（白）に対して、赤よりも高い事後確率を割り振っていることがわかります。<p>このように、訓練データ以外のデータに対しても、正しく推定を行うことの出来る能力を汎化能力と呼びます。<p>この言葉を使えば、「機械学習モデルの精度を上げること＝汎化能力を高めること」、と言うことが出来ます。<p>一方、訓練データに対しては百発百中だった図5のモデルはどうでしょうか。<p><img src=/images/blog/ol/image7.png alt="図7: 過学習が疑われるケース"><p>図7は、図5のモデルに対してテストデータ $ x&#39; $ を入力したら、正解のラベル（白）よりも不正解のラベル（赤）に高い事後確率が割り振られてしまった状態を示しています。<p>これは機械学習が汎化能力をもつことの妨げとなる、過学習(overfitting)の問題を端的に表したものとなっています。<h2 id=-overfitting->過学習(overfitting)とは</h2><p>過学習が起こる原因は様々ありますが、その一つはデータサイズが不十分であり、データの持つ非本質的な「癖」まで学習してしまうことです。<p>例えばこれまでの図において、訓練データ $ x_2 $ として登場していた旗揚げモデルの男の子を「Aくん」としてみましょう。<p><img src=/images/blog/ol/image8.png alt="図8: Aくんに着目"><p>ここでAくんは複数の訓練データにおいて登場しているとします。<p><img src=/images/blog/ol/image9.png alt="図9: Aくんを映した様々なデータ"><p>Aくんは赤色が好きなので、ついつい赤を揚げてしまうという「癖」があります。当然、これらの訓練データには赤のラベルが付与されています。<p>一方で、Aくんを映した訓練データには他にも特徴があります。<p><img src=/images/blog/ol/image10.png alt="図10: 本質的でないデータの特徴"><p>Aくんは背が小さいので、画像の上のほうに空白が空いてしまうのです。（ここで空白とは、ピクセル間のRGB値の変化が穏やかな領域のことと考え、またAくんの他に背の低い旗揚げモデルを映したデータは存在しないものとします。）<p>以上の議論をまとめると、今回使用した訓練データには、<p>「上のほうに空白が開いている画像は、赤を上げている」<p>という非本質的な「癖」があるといえます。<p>実は、図7のような出力がなされた理由は、機械学習モデルが入力データを入念に学習しすぎることよって、この特徴を覚え込んでしまったことだったのです。<p><img src=/images/blog/ol/image7.png alt="図7: 過学習が疑われるケース"><p>その結果として、Aくんと同様に「背が低い」未知の入力 $ x&#39; $ に対して、赤を揚げているという誤った推論をしてしまったのですね。<p>以上は、データの偏りによる過学習について述べました。他には、実際の振る舞いに比べてモデルの自由度が高すぎること等が、過学習の原因として考えられます。<h3 id=->過学習を防ぐための代表的な手法</h3><p>まず、十分なデータ数を用意することが重要です。<p>データを多様化しておくことで、先のように非本質的な癖を持つことを防ぐことが出来ます。<p>また、訓練データに対する誤差（二値分類においては対数尤度の総和）を訓練誤差と呼びますが、訓練誤差ばかりが小さくなり、テスト誤差が小さくならない（または大きくなっている）場合は、学習の効果が出ていないことになります。<p><img src=/images/blog/ol/image11.png alt="図11: 学習曲線"><p>上図は学習曲線(learning curve)と呼ばれるグラフで、エポック数（訓練データに対する学習回数）と誤差の関係を表しています。<p>（二値分類においては、対数尤度の総和にマイナスを付けた値を誤差として用いれば、尤度が1に近づくほど誤差が0に近づき、尤度が低くなると無限大に発散するような誤差関数を実現出来ます。）<p>上図で重要なのは、エポック数が増えるほど（訓練をすればするほど）訓練データに対する誤差は小さくなっているが、テストデータに対する誤差が次第に剥離し、やがて増大し始めているという点です。<p>このような時は学習を早期打ち切りすることによって、過学習を防ぐことが出来ます。<p>他に、モデルの自由度が高すぎることによる過学習を防ぐために、特にニューラルネットワークにおいて有用とされている手法として正則化(regularization)やドロップアウトがあります。これについては今後の記事で紹介していきます。</div></div><div id=blog-menu><span><strong>最近の記事</strong></span><ul><li class=recent><a href=/blog/algorithm/2017/05/30/db-ukey-detect2/ >2NF・3NF・BCNFは自動生成できる　データベース正規化アルゴリズムとその実装</a><li class=recent><a href=/blog/docker/2017/05/29/letsencript/ >非公開サイトをLet&#39;s EncryptなDockerコンテナでお手軽にSSL化する方法 | 開発環境のスピード構築のために</a><li class=recent><a href=/blog/algorithm/2017/04/28/db-ukey-detect/ >超高速開発とAIに関する一考察　DBにおける候補キーの自動検出アルゴリズムを書いてみた</a><li class=recent><a href=/blog/machine-learning/2017/03/29/online-learning/ >オンライン機械学習時代の到来が技術者にもたらすもの</a><li class=recent><a href=/blog/docker/2017/03/18/docker-mirror/ >社内の開発環境でDockerイメージをミラーリングする方法 | 開発環境のスピード構築</a></ul><span><strong>タグ</strong></span><ul><li class="tag-color-label tag__0"><a href=/blog/tag/%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%9F%E3%83%B3%E3%82%B0%E6%8A%80%E8%A1%93%E7%B7%8F%E8%A6%A7/ >プログラミング技術総覧 (11)</a><li class="tag-color-label tag__1"><a href=/blog/tag/Actor%E3%83%A2%E3%83%87%E3%83%AB/ >Actorモデル (1)</a><li class="tag-color-label tag__2"><a href=/blog/tag/%E3%83%AA%E3%82%A2%E3%82%AF%E3%83%86%E3%82%A3%E3%83%96%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%9F%E3%83%B3%E3%82%B0/ >リアクティブプログラミング (1)</a><li class="tag-color-label tag__3"><a href=/blog/tag/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92/ >機械学習 (5)</a><li class="tag-color-label tag__4"><a href=/blog/tag/%E9%9D%99%E7%9A%84%E3%82%B5%E3%82%A4%E3%83%88/ >静的サイト (1)</a><li class="tag-color-label tag__5"><a href=/blog/tag/%E7%92%B0%E5%A2%83%E6%A7%8B%E7%AF%89/ >環境構築 (4)</a><li class="tag-color-label tag__6"><a href=/blog/tag/Docker/ >Docker (4)</a><li class="tag-color-label tag__7"><a href=/blog/tag/AngularJS/ >AngularJS (2)</a><li class="tag-color-label tag__8"><a href=/blog/tag/React/ >React (2)</a><li class="tag-color-label tag__9"><a href=/blog/tag/%E3%82%A2%E3%83%AB%E3%82%BF%E3%82%B9%E3%83%95%E3%82%A1%E3%82%A4%E3%83%96/ >アルタスファイブ (2)</a><li class="tag-color-label tag__10"><a href=/blog/tag/Vagrant/ >Vagrant (1)</a><li class="tag-color-label tag__11"><a href=/blog/tag/%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%9F%E3%83%B3%E3%82%B0/ >プログラミング (1)</a><li class="tag-color-label tag__0"><a href=/blog/tag/Laravel/ >Laravel (1)</a><li class="tag-color-label tag__1"><a href=/blog/tag/OAuth/ >OAuth (1)</a><li class="tag-color-label tag__2"><a href=/blog/tag/%E3%82%A2%E3%83%AB%E3%82%B4%E3%83%AA%E3%82%BA%E3%83%A0/ >アルゴリズム (2)</a><li class="tag-color-label tag__3"><a href=/blog/tag/DB/ >DB (2)</a><li class="tag-color-label tag__4"><a href="/blog/tag/Let's%20Encrypt/">Let&#39;s Encrypt (1)</a></ul></div></div><div class=w_const><div id=fb-root></div><script>(function(d, s, id) {
            var js, fjs = d.getElementsByTagName(s)[0];
            if (d.getElementById(id)) return;
            js = d.createElement(s); js.id = id;
            js.src = "//connect.facebook.net/ja_JP/sdk.js#xfbml=1&version=v2.8&appId=331911723808007";
            fjs.parentNode.insertBefore(js, fjs);
          }(document, 'script', 'facebook-jssdk'));</script><ul class=socialbuttons><li class=twitter><a href=https://twitter.com/share class=twitter-share-button>Tweet</a><script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script><li class=facebook><div class=fb-like data-href={{articleUrl}} data-layout=box_count data-action=like data-size=small data-show-faces=false data-share=false></div><li class=googleplus><div class=g-plusone data-size=tall></div><script>window.___gcfg = {lang: 'ja'};
        
              (function() {
                var po = document.createElement('script'); po.type = 'text/javascript'; po.async = true;
                po.src = 'https://apis.google.com/js/platform.js';
                var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(po, s);
              })();</script><li class=hatena><a href="http://b.hatena.ne.jp/entry/{{articleUrl | url_param_escape}}" class=hatena-bookmark-button data-hatena-bookmark-title="{{articleTitle | url_param_escape}}" data-hatena-bookmark-layout=vertical-balloon data-hatena-bookmark-lang=ja title=このエントリーをはてなブックマークに追加><img src=https://b.st-hatena.com/images/entry-button/button-only@2x.png alt=このエントリーをはてなブックマークに追加 width=20 height=20 style="border: none"></a><script src=https://b.st-hatena.com/js/bookmark_button.js charset=utf-8 async></script><li class=pocket><a data-pocket-label=pocket data-pocket-count=vertical class=pocket-btn data-lang=ja></a><script>!function(d,i){if(!d.getElementById(i)){var j=d.createElement("script");j.id=i;j.src="https://widgets.getpocket.com/v1/j/btn.js?v=1";var w=d.getElementById(i);d.body.appendChild(j);}}(document,"pocket-btn-js");</script><li class=feedly><a href="//cloud.feedly.com/#subscription%2Ffeed%2F{{rssUrl | url_param_escape}}" target=blank><img id=feedlyFollow src=//s3.feedly.com/img/follows/feedly-follow-rectangle-volume-small_2x.png alt="follow us in feedly" width=66 height=20></a></ul><div class=relate><h1>関連記事</h1><ul><li class=post-link><span class=post-date>2017/03/30 </span><a class=post-title href=/blog/machine-learning/2017/03/29/online-learning/ >オンライン機械学習時代の到来が技術者にもたらすもの </a><span class=post-description><a href=/blog/machine-learning/2017/03/29/online-learning/ >「オンライン学習」とは、「データの到着が逐次的(sequential)であること」が解析に含まれているような機械学習手法を言います。いくつか、主要な概念やアルゴリズムについてまとめました。</a></span><li class=post-link><span class=post-date>2017/01/06 </span><a class=post-title href=/blog/machine-learning/2017/01/06/submodular2/ >オンライン広告をどのようにプロモーションする？ - 劣モジュラ性と局所探索で解決 </a><span class=post-description><a href=/blog/machine-learning/2017/01/06/submodular2/ >前回の記事でソーシャルマーケティングの例であるオンライン広告問題の定義と劣モジュラ性の関連について説明しました。今回はオンライン広告問題において、どのようにインフルエンサーを見つけ、プロモーションを行っていくのかを紹介したいと思います。</a></span><li class=post-link><span class=post-date>2016/12/28 </span><a class=post-title href=/blog/machine-learning/2016/12/28/submodular1/ >ソーシャルマーケティングシステムを単純なアルゴリズムで実装する - 劣モジュラ最適化と貪欲法 </a><span class=post-description><a href=/blog/machine-learning/2016/12/28/submodular1/ >ソーシャルメディアを用いたバイラルマーケティングの例は多数あります。実は、このバイラルマーケティングの裏には、劣モジュラ性という数学的性質に基づいて設計されたシステムが使われています。</a></span><li class=post-link><span class=post-date>2016/11/19 </span><a class=post-title href=/blog/machine-learning/2016/11/18/nnet/ >ニューラルネットワークの考え方とライブラリ </a><span class=post-description><a href=/blog/machine-learning/2016/11/18/nnet/ >ニューラルネットワークという数学モデルの働きについての解説と、プログラムに使えるライブラリを紹介します。</a></span><li class=post-link><span class=post-date>2017/05/30 </span><a class=post-title href=/blog/algorithm/2017/05/30/db-ukey-detect2/ >2NF・3NF・BCNFは自動生成できる　データベース正規化アルゴリズムとその実装 </a><span class=post-description><a href=/blog/algorithm/2017/05/30/db-ukey-detect2/ >今回は、第二正規形（2NF）までの正規化を行うアルゴリズムを提案・実装しています。2NF、3NF、BCNFはいずれも、関数従属性を取り扱うという点で共通しています。なので、2NFの自動化ができれば、3NFやBCNFへのステップアップにはさほどの困難はなさそうです。</a></span></ul></div></div></article><article id=scout class=article><h1 class="scout_title w_const">＼(＾▽＾*) 私たちと一緒に働いてみませんか？ (*＾▽＾)／</h1><div class="article__conts w_const"><section class="content01 content"><p>少しでも興味をお持ちいただけたら、お気軽に、お問い合わせください。<p><a href=/contact/entry/ >採用応募受付へ</a><p>(採用応募じゃなく、ただ、会ってみたいという方も、大歓迎です。)</section></div></article></div><footer id=_footer><nav class=w_const><div class="content01 cf"><div class=profile><h1 class=foot_logo><a href=/ ><img src=/images/logo_footer.png alt=Altus-Five（アルタスファイブ）></a></h1><div class=address><p class=paragraph>〒160-0022<p class=paragraph>東京都新宿区新宿2-1-9 ステラ新宿5F<p class=paragraph><a href=tel:03-6904-5573>TEL：03-6904-5573</a></div></div><ul class="links links01"><li class=link><a href=/ >TOP</a><li class=link><a href=/#introduction>アルタスファイブとは</a><li class=link><a href=/#feature>強み</a><li class=link><a href=/#service>サービス</a><li class=link><a href=/#performance>実績</a><li class=link><a href=/#example>開発事例</a><li class=link><a href=/blog/ >ブログ</a></ul><ul class="links links02"><li class=link><a href=/recruit/ >採用情報</a><li class=link><a href=/company/ >会社概要</a><li class=link><a href=/privacy/ >個人情報保護方針</a><li class=link><a href=/contact/ >お問い合わせ</a></ul><ul class=marks><li class=mark><img src=/images/p_mark.png alt=""></ul></div><div id=copyright>© 2016 Altus-Five Co.,LTD. ALL RIGHTS RESERVED.</div></nav></footer><script src=/scripts/vendor.js></script><script>$(function() {
      var fout = false;
      var orgFontFamily;
      if (fout) {
        var orgFontFamily = $('body').css('font-family');
        $('body').css({'font-family': "'Helvetica', 'Arial', 'メイリオ', 'Meiryo', 'MS  PGothic', 'ヒラギノ角ゴ Pro W3', 'Hiragino Kaku Gothic Pro', sans-serif"});
      }
      WebFont.load({
        google: {
          families: [
            "PT Sans Narrow:n4,n7"
          ]
        },
        custom: {
          families: [
            "Noto Sans Japanese:n4,n7"
          ]
        },
        timeout: 3000,
        loading: function() {
          // ロードしているとき allfonts
        },
        active: function() {
          // Web Fontが使用可能になったとき allfonts
        },
        inactive: function() {
          // ブラウザがサポートしていないとき allfonts
        },
        fontloading: function(fontFamily, fontDescription) {
          // fontFamilyをロードしているとき onefont
        },
        fontactive: function(fontFamily, fontDescription) {
          // fontFamilyが使用可能になったとき onefont
          if (fout) {
            if ('Noto Sans Japanese' === fontFamily) {
              $('body').css({'font-family': orgFontFamily});
            }
          }
        },
        fontinactive: function(fontFamily, fontDescription) {
          // fontFamilyをブラウザがサポートしていないとき onefont
        }
      });
    });</script><script src=/scripts/common.js></script><script src=/scripts/jquery.tile.min.js></script><script type=text/x-mathjax-config>MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ['\\(','\\)'] ],
        processEscapes: true
      }
    });</script><script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML"></script>